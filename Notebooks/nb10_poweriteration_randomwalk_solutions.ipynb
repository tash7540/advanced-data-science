{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 10: Power Iteration and Random Walks\n",
    "***\n",
    "\n",
    "In this notebook we'll run through an example using power iteration and have a closer look at the random walk interpretation of PageRank.\n",
    "\n",
    "We'll need numpy for this notebook, so let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 1: Power Iteration\n",
    "\n",
    "Consider the small web of 5 pages depicted below.\n",
    "\n",
    "<img width=250px src=\"http://www.cs.colorado.edu/~anwo7157/home/resources/pagerank1.png\">\n",
    "\n",
    "First, let's form a hypothesis about which page(s) will have the highest page rank, and which will have the lowest. What evidence in the graph suggests those pages will have high/low rank?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Page 1 has the most in-links, so we would suppose it should have a high rank. Page 2 has an in-link from Page 1, so it might also have a high rank. Page 4 only has 1 in-link, so it probably has low rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up the stochastic adjacency matrix $M$ for this graph. Use the natural order 1-5 for the rows/columns. Recall that $M_{ji} = 1/\\text{degree}(i)$ if there is a link from $i$ to $j$, otherwise $M_{ji} = 0$. The first row is done for you, depicting the in-links to Page 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-62da89360792>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# TODO -- fill in the rest of M\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "M = np.zeros((n,n))\n",
    "M[0,:] = [0, 0, 1/2, 1/3, 1/3]\n",
    "# TODO -- fill in the rest of M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "M = np.array([[0, 0, 1/2, 1/3, 1/3],\n",
    "              [1, 0, 0  , 0  , 1/3],\n",
    "              [0, 0, 0  , 1/3, 1/3],\n",
    "              [0, 0, 1/2, 0  , 0  ],\n",
    "              [0, 1, 0  , 1/3, 0  ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute something(s) to make sure that $M$ is indeed a ***column-stochastic*** matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of column 0 is: 1.0\n",
      "Sum of column 1 is: 1.0\n",
      "Sum of column 2 is: 1.0\n",
      "Sum of column 3 is: 1.0\n",
      "Sum of column 4 is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "for k in range(N):\n",
    "    print(\"Sum of column {} is: {}\".format(k, np.sum(M[:,k])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform power iteration, we need to initialize our PageRank vector, $r$. Our solution shouldn't rely critically on how we do this, but an easy first option is to evenly distribute the rank among all $N$ pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.repeat(1/N, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single iteration of power iteration involves multiplying $M$ by the PageRank vector $r$, which effective \"moves\" rank around. Perform a single iteration, but save both the old and the new rank vectors so we can compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_old = r.copy()\n",
    "r_new = np.matmul(M, r_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we iterate many more times trying to converge our estimate for the rank vector, we will need a ***distance measure*** between old and new rank vectors, to detect when our estimates are converged. We can use the $L_1$ norm:\n",
    "$$d(\\vec{x}, \\vec{y}) = \\sum_{i=1}^N |x_i - y_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_L1(x,y):\n",
    "    return np.sum(np.abs(np.array(x)-np.array(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the distance between the old and new rank vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(r_old, r_new) = 0.3333\n"
     ]
    }
   ],
   "source": [
    "print(\"d(r_old, r_new) = {:0.4f}\".format(dist_L1(r_old, r_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pick a tolerance for when to decide our power iteration has converged. We'll use a tolerance of 0.001 here, but note that in reality, we may want to use stricter tolerances, depending on how much is at stake (like, whether a website appears on the first page of our internet search or not).\n",
    "\n",
    "Use a `while` loop to perform power iteration until it converges. Keep track of how many iterations are performed (including the one above) and print out the estimate of the rank vector each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-4ae21e277fd0>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-4ae21e277fd0>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    while ???: # TODO -- your code goes here!\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tol = 0.001\n",
    "iters = 1\n",
    "print(\"{:2.0f}  {:0.3f}  {:0.3f}  {:0.3f}  {:0.3f}  {:0.3f}\".format(0, r[0],r[1],r[2],r[3],r[4]))\n",
    "while ???: # TODO -- your code goes here!\n",
    "    # TODO -- and here!\n",
    "    print(\"{:2.0f}  {:0.3f}  {:0.3f}  {:0.3f}  {:0.3f}\".format(iters, r_new[0],r_new[1],r_new[2],r_new[3],r_new[4]))\n",
    "    # TODO -- and maybe here too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  0.200  0.200  0.200  0.200  0.200\n",
      " 1  0.189  0.322  0.122  0.067  0.300\n",
      " 2  0.183  0.289  0.122  0.061  0.344\n",
      " 3  0.196  0.298  0.135  0.061  0.309\n",
      " 4  0.191  0.299  0.123  0.068  0.319\n",
      " 5  0.190  0.297  0.129  0.062  0.322\n",
      " 6  0.192  0.298  0.128  0.064  0.318\n",
      " 7  0.191  0.298  0.127  0.064  0.319\n",
      " 8  0.191  0.298  0.128  0.064  0.319\n",
      " 9  0.192  0.298  0.128  0.064  0.319\n",
      "10  0.191  0.298  0.128  0.064  0.319\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "tol = 0.001\n",
    "iters = 1\n",
    "print(\"{:2.0f}  {:0.3f}  {:0.3f}  {:0.3f}  {:0.3f}  {:0.3f}\".format(0, r[0],r[1],r[2],r[3],r[4]))\n",
    "while dist_L1(r_old, r_new) > tol:\n",
    "    r_old = r_new.copy()\n",
    "    r_new = np.matmul(M, r_old)\n",
    "    print(\"{:2.0f}  {:0.3f}  {:0.3f}  {:0.3f}  {:0.3f}  {:0.3f}\".format(iters, r_new[0],r_new[1],r_new[2],r_new[3],r_new[4]))\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the computed PageRanks compare to your hypothesis? In particular, can you explain:\n",
    "* Why does Page 2 have higher rank than Page 1? This seems crazy because Page 1 has so many in-links! What's up with that?\n",
    "* Why does Page 5 have the highest rank?\n",
    "* Any other funky structure you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercise 2:  Random Walking\n",
    "\n",
    "PageRank can equivalently be thought of in terms of an imaginary Tron-style person walking around on the internet. As the walker moves, she randomly follows one of the out-links from the current page to another one (possibly back to the current page, if there are self-links). Each step can be considered a point in time, during which the walker is at exactly one of the pages. A page's PageRank is the long-run proportion of time that the walker spends on that page. Here, \"long-run\" means we need the walker to move around for a very long time. If you have taken prob/stats classes covering *Markov chains* before, and/or were paying close attention during lecture, you are probably hissing *stationary distribution!* under your breath. That's perfectly normal.\n",
    "\n",
    "So, we could also estimate PageRank by simulating a random walk on the graph defined above. Suppose the walker starts at Page 1. Then the first column of $M$ defines the probabilities of the walker landing in any of the other pages. In this case, she goes to Page 2 with probability 1 since that is the only out-link from Page 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.5        0.33333333 0.33333333]\n",
      " [1.         0.         0.         0.         0.33333333]\n",
      " [0.         0.         0.         0.33333333 0.33333333]\n",
      " [0.         0.         0.5        0.         0.        ]\n",
      " [0.         1.         0.         0.33333333 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go for a walk, shall we?\n",
    "\n",
    "We need a list to track all of the Pages the walker has visited, and we can start her off at Page 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4022)\n",
    "\n",
    "# Keep track of all the pages visited \n",
    "visited_pages = []\n",
    "all_pages = list(range(1, M.shape[0]+1))\n",
    "\n",
    "# Start the walker on Page 1\n",
    "current_page = 1\n",
    "visited_pages.append(current_page)\n",
    "\n",
    "# Pick a random new page\n",
    "new_page = np.random.choice(all_pages, p=M[:,current_page-1])\n",
    "print(new_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reset the current page to the new one, save it to `visited_pages`, and continue to step forward in this manner a great many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step forward\n",
    "current_page = new_page\n",
    "visited_pages.append(current_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this using a fixed number of iterations, or until we reach some convergence criterion as a stopping condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "np.random.seed(4022)\n",
    "visited_pages = []\n",
    "all_pages = list(range(1, M.shape[0]+1))\n",
    "current_page = 1  # Start the walker on Page 1\n",
    "visited_pages.append(current_page)\n",
    "niter = 100\n",
    "\n",
    "# Iterate\n",
    "for _ in range(niter):\n",
    "    new_page = np.random.choice(all_pages, p=M[:,current_page-1])\n",
    "    visited_pages.append(new_page)\n",
    "    current_page = new_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the proportion of iterations that the walker spent on each page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19, 0.28, 0.15, 0.08, 0.3]\n"
     ]
    }
   ],
   "source": [
    "r_walk = [np.sum([visited_pages[k]==p for k in range(niter)])/niter for p in all_pages]\n",
    "print(r_walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare to our final PageRank estimate from power iteration in Exercise 1? What does this say about whether or not we have run our random walk for a sufficient length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19146329 0.29789476 0.12760155 0.06386174 0.31917867]\n"
     ]
    }
   ],
   "source": [
    "print(r_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the random walk for a total of 50,000 iterations, and check again how similar the estimated PageRanks are to the ranks from power iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19092, 0.2975, 0.12912, 0.06404, 0.31842]\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "# Initialize\n",
    "np.random.seed(4022)\n",
    "visited_pages = []\n",
    "all_pages = list(range(1, M.shape[0]+1))\n",
    "current_page = 1  # Start the walker on Page 1\n",
    "visited_pages.append(current_page)\n",
    "niter = 50000\n",
    "\n",
    "# Iterate\n",
    "for _ in range(niter):\n",
    "    new_page = np.random.choice(all_pages, p=M[:,current_page-1])\n",
    "    visited_pages.append(new_page)\n",
    "    current_page = new_page\n",
    "    \n",
    "r_walk = [np.sum([visited_pages[k]==p for k in range(niter)])/niter for p in all_pages]\n",
    "print(r_walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what it means for $\\vec{r}$ to be a stationary distribution of this random walk:  $\\vec{r}$ must satisfy the equation $\\vec{r} = M \\vec{r}$.\n",
    "\n",
    "Based on this, and what you know from earlier in the semester about ways to measure the distance between two vectors, can you come up with another way to evaluate how well the random walk has converged to the stationary distribution (and therefore to the actual PageRanks)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021408409562599672\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "# can use any kind of distance. here is the euclidean distance:\n",
    "err = np.sqrt(np.sum((r_walk - np.matmul(M, r_walk))**2))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
