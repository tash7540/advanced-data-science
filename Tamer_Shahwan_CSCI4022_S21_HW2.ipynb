{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI4022 Homework 2; Review\n",
    "\n",
    "## Due Monday, February 8 at 11:59 pm to Canvas\n",
    "\n",
    "#### Submit this file as a .ipynb with *all cells compiled and run* to the associated dropbox.\n",
    "\n",
    "***\n",
    "\n",
    "Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Here is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.  I also recommend the [wikibook](https://en.wikibooks.org/wiki/LaTeX) for LaTex.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do **Kernel $\\rightarrow$ Restart & Run All** as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- 45 points of this assignment are in problems.  The remaining 5 are for neatness, style, and overall exposition of both code and text.\n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "- There is *not a prescribed API* for these problems.  You may answer coding questions with whatever syntax or object typing you deem fit.  Your evaluation will primarily live in the clarity of how well you present your final results, so don't skip over any interpretations!  Your code should still be commented and readable to ensure you followed the given course algorithm.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p1'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 1 (Theory: minhashing; 10 pts)\n",
    "\n",
    "Consider minhash values for a single column vector that contains 10 components/rows. Seven of rows hold 0 and three hold 1. Consider taking all 10! = 3,628,800 possible distinct permutations of ten rows. When we choose a permutation of the rows and produce a minhash value for the column, we will use the number of the row, in the permuted order, that is the first with a 1.  Use Markdown cells to demonstrate answers to the following.\n",
    "\n",
    "#### a) For exactly how many of the 3,628,800 permutations is the minhash value for the column a 9?  What proportion is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None. Because in the worst case we have all seven 0 first (in the 1-7 digits), so the 8th digit will be a 1 making it impposible for 9 to be the value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) For exactly how many of the 3,628,800 permutations is the minhash value for the column a 8?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This happens when all first seven digits are 0. any of the seven 0 can take digit 1, and any of the seven 0 can take on digit two and so on... so 7^7 = 823543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) For exactly how many of the 3,628,800 permutations is the minhash value for the column a 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This happens when first two digits are 0 and the third is a 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a/ id='p3'></a>\n",
    "[Back to top](#top)\n",
    "# Problem 2 (Applied Minhashing; 35 pts)\n",
    "\n",
    "In this problem we compare similarities of 5 documents available on http://www.gutenberg.org\n",
    "\n",
    " 1) The first approximately 10000 characters of Miguel de Unamuno's *Niebla*, written in Spanish, in the file `niebla.txt`\n",
    " \n",
    " 2) The first approximately 10000 characters of Miguel de Cervantes *The Ingenious Gentleman Don Quixote of La Mancha*, written in Spanish, in the file `DQ.txt`\n",
    " \n",
    " 3) The first approximately 10000 characters of Homer's *The Odyssey*, translated into English by Samuel Butler, in the file `odyssey.txt`\n",
    " \n",
    " 4) The first approximately 10000 characters of Kate Chopin's *The Awakening* in the file `awaken.txt`\n",
    " \n",
    " 5) The entirety of around 12000 characters of Kate Chopin's *Beyond the Bayou* in the file `BB.txt`\n",
    " \n",
    "### a) Clean the 4 documents, scrubbing all punctuation, changes cases to lower case, and removing accent marks as appropriate.  \n",
    "\n",
    "You should have only 27 unique characters in each book/section after cleaning, corresponding to white spaces and the 26 letters.  \n",
    "\n",
    "\n",
    "**For this problem, you may import any text-based packages you desire to help wrangle the data.**  I recommend looking at some functions within `string` or the RegEx `re` packages.\n",
    "\n",
    "You can and probably should use functions in the string package such as `string.lower`, `string.replace`, etc.\n",
    "\n",
    "All 5 documents have been saved in UTF-8 encoding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfR_ody = pd.read_fwf('/users/tamer/desktop/advanced_ds/data/odyssey.txt',names = ['odyssey'])\n",
    "dfR_niebla = pd.read_fwf('/users/tamer/desktop/advanced_ds/data/niebla.txt',names = ['niebla'])\n",
    "dfR_DQ = pd.read_fwf('/users/tamer/desktop/advanced_ds/data/DQ.txt',names = ['DQ'])\n",
    "dfR_awaken = pd.read_fwf('/users/tamer/desktop/advanced_ds/data/awaken.txt',names = ['awaken'])\n",
    "dfR_BB = pd.read_fwf('/users/tamer/desktop/advanced_ds/data/BB.txt',names = ['BB'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not proud of this implementation, but it works. Here after I cleaned my data then I converted my data frames into lists\n",
    "niebla,dq,odyssey,awaken,bb = [],[],[],[],[]\n",
    "dfR_niebla['niebla'] = dfR_niebla['niebla'].replace('[^a-z A-Z]','',regex=True)\n",
    "dfR_DQ['DQ'] = dfR_DQ['DQ'].replace('[^a-z A-Z]','',regex=True)\n",
    "dfR_ody['odyssey'] = dfR_ody['odyssey'].replace('[^a-z A-Z]','',regex=True)\n",
    "dfR_awaken['awaken'] = dfR_awaken['awaken'].replace('[^a-z A-Z]','',regex=True)\n",
    "dfR_BB['BB'] = dfR_BB['BB'].replace('[^a-z A-Z]','',regex=True)\n",
    "\n",
    "for i in dfR_niebla['niebla']:\n",
    "    niebla.append(i.lower())\n",
    "    \n",
    "for i in dfR_DQ['DQ']:\n",
    "    dq.append(i.lower())\n",
    "    \n",
    "for i in dfR_ody['odyssey']:\n",
    "    odyssey.append(i.lower())\n",
    "    \n",
    "for i in dfR_awaken['awaken']:\n",
    "    awaken.append(i.lower())\n",
    "    \n",
    "for i in dfR_BB['BB']:\n",
    "    bb.append(i.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b) Compute exact similarity scores between the documents.  Are these the expected results?\n",
    "\n",
    "Notes:\n",
    "- You may choose or explore different values of $k$ for your shingles.\n",
    "- You may choose to shingle on words and create an n-gram model, but it is recommended you shingle on letters as described in class\n",
    "- You may construct your characteristic matrix or characteristic sets with or without hash functions (e.g. by using `set()`).  Note that choice of hash function should change heavily with $k$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "niebla similarity to niebla = 1.0\n",
      "niebla similarity to dq = 0.1641156462585034\n",
      "niebla similarity to odyssey = 0.047635021804763505\n",
      "niebla similarity to awaken = 0.04577822990844354\n",
      "niebla similarity to bb = 0.04528061224489796\n",
      "-----------------------------------------\n",
      "dq similarity to niebla = 0.1641156462585034\n",
      "dq similarity to dq = 1.0\n",
      "dq similarity to odyssey = 0.03971789161098738\n",
      "dq similarity to awaken = 0.041085563513004145\n",
      "dq similarity to bb = 0.04526166902404526\n",
      "-----------------------------------------\n",
      "odyssey similarity to niebla = 0.047635021804763505\n",
      "odyssey similarity to dq = 0.03971789161098738\n",
      "odyssey similarity to odyssey = 1.0\n",
      "odyssey similarity to awaken = 0.1897920604914934\n",
      "odyssey similarity to bb = 0.1944941008223096\n",
      "-----------------------------------------\n",
      "awaken similarity to niebla = 0.04577822990844354\n",
      "awaken similarity to dq = 0.041085563513004145\n",
      "awaken similarity to odyssey = 0.1897920604914934\n",
      "awaken similarity to awaken = 1.0\n",
      "awaken similarity to bb = 0.19507781397032212\n",
      "-----------------------------------------\n",
      "bb similarity to niebla = 0.04528061224489796\n",
      "bb similarity to dq = 0.04526166902404526\n",
      "bb similarity to odyssey = 0.1944941008223096\n",
      "bb similarity to awaken = 0.19507781397032212\n",
      "bb similarity to bb = 1.0\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# merge list elements into one element found at https://stackoverflow.com/questions/12453580/how-to-concatenate-items-in-a-list-to-a-single-string\n",
    "\n",
    "# initilize 5 sets to hold shingles.\n",
    "shingles_niebla,shingles_dq,shingles_odyssey,shingles_awaken,shingles_bb =set(),set(),set(),set(),set()\n",
    "\n",
    "#initilize 5 strings to hold the 5 documents\n",
    "niebla_string, dq_string, odyssey_string, awaken_string, bb_string = \"\",\"\",\"\",\"\",\"\"\n",
    "\n",
    "# convert documents to one huge string\n",
    "niebla_string, dq_string, odyssey_string, awaken_string, bb_string=' '.join(niebla) ,' '.join(dq) ,' '.join(odyssey),' '.join(awaken),' '.join(bb)  \n",
    "\n",
    "#sizes of each of the documents (used in each of the documents loops)\n",
    "niebla_size, dq_size, odyssey_size, awaken_size, bb_size =len(niebla_string) ,len(dq_string) ,len(odyssey_string),len(awaken_string),len(bb_string)   \n",
    "\n",
    "k = 4 # number of shingles we choose (letters)\n",
    "\n",
    "# here we shingle(length k). I will do 5 loops, one for each of the documents( ugly but works just fine)\n",
    "\n",
    "\n",
    "start = 0 # we start at 0\n",
    "end = k # marking the end of a shingle\n",
    "while start < niebla_size:\n",
    "    \n",
    "    shingles_niebla.add(niebla_string[start:end]) \n",
    "    start = start + k \n",
    "    end = end + k\n",
    "    \n",
    "\n",
    "start = 0 # we start at 0\n",
    "end = k # marking the end of a shingle\n",
    "while start < dq_size:\n",
    "    \n",
    "    shingles_dq.add(dq_string[start:end]) \n",
    "    start = start + k \n",
    "    end = end + k    \n",
    "\n",
    "    \n",
    "start = 0 # we start at 0\n",
    "end = k # marking the end of a shingle\n",
    "while start < odyssey_size:\n",
    "    \n",
    "    shingles_odyssey.add(odyssey_string[start:end]) \n",
    "    start = start + k \n",
    "    end = end + k\n",
    "    \n",
    "    \n",
    "start = 0 # we start at 0\n",
    "end = k # marking the end of a shingle\n",
    "while start < awaken_size:\n",
    "    \n",
    "    shingles_awaken.add(awaken_string[start:end]) \n",
    "    start = start + k \n",
    "    end = end + k\n",
    "    \n",
    "    \n",
    "    \n",
    "start = 0 # we start at 0\n",
    "end = k # marking the end of a shingle\n",
    "while start < bb_size:\n",
    "    \n",
    "    shingles_bb.add(bb_string[start:end]) \n",
    "    start = start + k \n",
    "    end = end + k\n",
    "  \n",
    "\n",
    "name = ['niebla','dq','odyssey','awaken','bb'] \n",
    "shingles = [shingles_niebla,shingles_dq,shingles_odyssey,shingles_awaken,shingles_bb]\n",
    "for j in range(5):\n",
    "    for i in range(5):\n",
    "    \n",
    "        print(name[j] ,\"similarity to\", name[i],\"=\", len(shingles[j].intersection(shingles[i]))/len(shingles[j].union(shingles[i])))\n",
    "    print(\"-----------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is showing that niebla and bq are similar. And oddyssey,bb nd awaken are similar. This is expected since niebla and bq are both in spanish while the others are in english.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Implement minhashing with 1000 hash functions on the 4 documents, checking your results against those in part b).\n",
    "\n",
    "- You may choose your own value of $p$ as the modulus of the hash functions.  You are encouraged to use the example code from the minhashing in class notebook to start you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      niebla  dq  odyssey  awaken  bb\n",
      "0          1   0        0       0   0\n",
      "1          0   0        1       0   0\n",
      "2          1   0        0       0   0\n",
      "3          0   0        1       0   0\n",
      "4          1   1        0       1   0\n",
      "...      ...  ..      ...     ...  ..\n",
      "5546       0   0        1       0   1\n",
      "5547       0   0        0       0   1\n",
      "5548       1   0        0       0   0\n",
      "5549       0   0        1       1   0\n",
      "5550       0   0        0       1   1\n",
      "\n",
      "[5551 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#here im trying to construct a charactristic matrix from the emplementation above,\n",
    "#so i can feed it directly to my borrowed min hash function\n",
    "\n",
    "#\"everything\" holds the union of all shingles(non repeating)\n",
    "everything = shingles_niebla.union(shingles_dq) \n",
    "everything = everything.union(shingles_odyssey)\n",
    "everything = everything.union(shingles_awaken)\n",
    "everything = everything.union(shingles_bb)\n",
    "\n",
    "niebla,dq,odyssey,awaken,bb = [],[],[],[],[]\n",
    "everything = pd.DataFrame(everything,columns= ['index'])\n",
    "#loop over all shingles(evertything) and ask if it is in each of the 'shingles' constructed above,\n",
    "#then we merge al of them together into one df called char_mat\n",
    "for i in everything['index']:\n",
    "    \n",
    "    if i in shingles_niebla:\n",
    "        niebla.append(1)\n",
    "    else:\n",
    "        niebla.append(0)\n",
    "        \n",
    "    if i in shingles_dq:\n",
    "        dq.append(1)\n",
    "    else:\n",
    "        dq.append(0)\n",
    "        \n",
    "    if i in shingles_odyssey:\n",
    "        odyssey.append(1)\n",
    "    else:\n",
    "        odyssey.append(0)\n",
    "        \n",
    "    if i in shingles_awaken:\n",
    "        awaken.append(1)\n",
    "    else:\n",
    "        awaken.append(0)\n",
    "        \n",
    "    if i in shingles_bb:\n",
    "        bb.append(1)\n",
    "    else:\n",
    "        bb.append(0)\n",
    "    \n",
    "char_mat = pd.DataFrame({'niebla':niebla,'dq':dq,'odyssey':odyssey,'awaken':awaken,'bb':bb},columns=name)\n",
    "\n",
    "print(char_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: notebooks\n",
    "#feed above char matrix to minhash with 1000 hash functions. we have around 5.5k rows so we need a prime(Phash) larger than that\n",
    "\n",
    "def minhash(nhash, dfC):\n",
    "    '''\n",
    "    Takes a number of hash functions to use (nhash) and characteristic matrix (dfC)\n",
    "    '''\n",
    "    # use the \"universal hash\":  (a*x+b) mod p, where a, b are random ints and p > N (= 10 here) is prime\n",
    "    np.random.seed(4022)\n",
    "    Ahash = np.random.choice(range(0,10000), size=nhash)\n",
    "    Bhash = np.random.choice(range(0,10000), size=nhash)\n",
    "    Phash =   5701  #prime bigger than 5551\n",
    "\n",
    "    # STEP 2:  initialize signature matrix to all infinities\n",
    "\n",
    "    # initialize the signature matrix\n",
    "    Msig = np.full([nhash, len(dfC.columns)], fill_value=np.inf)\n",
    "\n",
    "    # fill in the signature matrix:\n",
    "\n",
    "    # For each row of the characteristic matrix... \n",
    "    hash_vals = [0]*nhash # initialize\n",
    "    for r in range(len(dfC)):\n",
    "        # STEP 3:  Compute hash values (~permuted row numbers) for that row under each hash function\n",
    "        for h in range(nhash):\n",
    "            hash_vals[h] = (Ahash[h]*r + Bhash[h])%Phash\n",
    "        # STEP 4:  For each column, if there is a 0, do nothing...\n",
    "        for c in range(len(dfC.columns)):\n",
    "            # ... but if there is a 1, replace signature matrix element in that column for each hash fcn \n",
    "            # with the minimum of the hash value in this row, and the current signature matrix element\n",
    "            if dfC.iloc[r,c]==1:\n",
    "                for h in range(nhash):\n",
    "                    if hash_vals[h] < Msig[h,c]:\n",
    "                        Msig[h,c] = hash_vals[h]\n",
    "    return Msig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0. 10.  7.  1.]\n",
      " [ 0.  2.  1.  5.  4.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  1.  2.  1.  7.]\n",
      " [ 4.  1.  0.  3.  0.]\n",
      " [ 1.  4.  0.  3.  2.]]\n"
     ]
    }
   ],
   "source": [
    "m_sig = minhash(1000,char_mat)\n",
    "print(m_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "niebla similarity to niebla = 1.0\n",
      "niebla similarity to dq = 0.175\n",
      "niebla similarity to odyssey = 0.049\n",
      "niebla similarity to awaken = 0.057\n",
      "niebla similarity to bb = 0.043\n",
      "-----------------------\n",
      "dq similarity to niebla = 0.175\n",
      "dq similarity to dq = 1.0\n",
      "dq similarity to odyssey = 0.035\n",
      "dq similarity to awaken = 0.034\n",
      "dq similarity to bb = 0.038\n",
      "-----------------------\n",
      "odyssey similarity to niebla = 0.049\n",
      "odyssey similarity to dq = 0.035\n",
      "odyssey similarity to odyssey = 1.0\n",
      "odyssey similarity to awaken = 0.196\n",
      "odyssey similarity to bb = 0.221\n",
      "-----------------------\n",
      "awaken similarity to niebla = 0.057\n",
      "awaken similarity to dq = 0.034\n",
      "awaken similarity to odyssey = 0.196\n",
      "awaken similarity to awaken = 1.0\n",
      "awaken similarity to bb = 0.214\n",
      "-----------------------\n",
      "bb similarity to niebla = 0.043\n",
      "bb similarity to dq = 0.038\n",
      "bb similarity to odyssey = 0.221\n",
      "bb similarity to awaken = 0.214\n",
      "bb similarity to bb = 1.0\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        print(name[i],\"similarity to\",name[j],\"=\",sum(m_sig[:,i]==m_sig[:,j])/1000)\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Discussion:\n",
    "\n",
    "Can we detect expected differences here?  Are the two Spanish docuemnts most similar to each other?  Are the two documents by the same author, with the same theme, the most similar?  What kind of alternatives might have captured the structures between these texts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minhash solution looks pretty much like the exact calculation soltuion. I can see that the two Spanish documents are more similar to each other than they are to the english documents, since their similarity scores are in the tenth decimal point while the other are in the thousands decimal point. following the same proccess, I can see that the English documents are more similar to each other than the Spanish documents. The two documents with the same author don't seem more similar to each other than the third (good author?). One good alternative would be author's age. Example: two authors could have more similar writing if they are in the same agr group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
